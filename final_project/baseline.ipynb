{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jackh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jackh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assume you have a pandas DataFrame named `articles` with 'abstracts', 'keywords', and 'titles' columns\n",
    "articles = pd.read_csv('E:/CS554 - NLP/final_project/NYT/NYT_Dataset_Preprocessed.csv')  # Replace with your actual dataset\n",
    "\n",
    "articles = articles[articles['preprocessed_abstract'] != '']\n",
    "articles = articles[articles['preprocessed_title'] != '']\n",
    "articles = articles[articles['preprocessed_keywords'] != '']\n",
    "\n",
    "articles = articles[(articles['preprocessed_abstract'].apply(type) == str) &\n",
    "                    (articles['preprocessed_title'].apply(type) == str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_keywords_row(keyword_string):\n",
    "    # Convert string representation of list to actual list\n",
    "    keywords = ast.literal_eval(keyword_string)\n",
    "    processed_keywords = []\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        # Convert to lowercase\n",
    "        keyword = keyword.lower()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        keyword = keyword.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        \n",
    "        # Tokenize\n",
    "        words = word_tokenize(keyword)\n",
    "        \n",
    "        # Remove stop words and duplicates\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Remove duplicates while maintaining order\n",
    "        filtered_words = list(dict.fromkeys(filtered_words))\n",
    "        \n",
    "        # Join back into a processed string\n",
    "        processed_keywords.append(\" \".join(filtered_words))\n",
    "\n",
    "    kws = ''\n",
    "\n",
    "    for keys in processed_keywords:\n",
    "        kws += keys + \" \"\n",
    "    \n",
    "    return kws[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['processed_keywords'] = articles['preprocessed_keywords'].apply(preprocess_keywords_row)\n",
    "\n",
    "# Combine abstracts and keywords\n",
    "articles['input_text'] = articles['preprocessed_abstract'] + ' ' + articles['processed_keywords']\n",
    "\n",
    "# Use SentenceTransformer to generate embeddings\n",
    "sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')  # A lightweight model for sentence embeddings\n",
    "\n",
    "# Generate embeddings\n",
    "articles['input_embeddings'] = articles['input_text'].apply(lambda x: sentence_transformer.encode(x))\n",
    "articles['title_embeddings'] = articles['preprocessed_title'].apply(lambda x: sentence_transformer.encode(x))\n",
    "\n",
    "# Convert embeddings to arrays\n",
    "X = np.vstack(articles['input_embeddings'])\n",
    "y = np.vstack(articles['title_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "# Create PyTorch dataset\n",
    "dataset = EmbeddingDataset(X, y)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence length dimension (seq_len = 1)\n",
    "        x = x.unsqueeze(1)  # Shape: (batch_size, seq_len=1, input_size)\n",
    "        # print(f\"Input to encoder: {x.shape}\")  # Debugging print\n",
    "\n",
    "        # Encode input\n",
    "        _, (hidden, cell) = self.encoder(x)  # Hidden and cell have shape (1, batch_size, hidden_size)\n",
    "        # print(f\"Encoder hidden state: {hidden.shape}, cell state: {cell.shape}\")\n",
    "\n",
    "        # Decoder expects (seq_len, batch_size, hidden_size)\n",
    "        # Reshape hidden state for decoder input\n",
    "        decoder_input = hidden.transpose(0, 1)  # Shape: (batch_size, seq_len=1, hidden_size)\n",
    "        # print(f\"Input to decoder: {decoder_input.shape}\")\n",
    "\n",
    "        # Decode using hidden state and cell state\n",
    "        decoder_outputs, _ = self.decoder(decoder_input)  # Outputs: (batch_size, seq_len=1, hidden_size)\n",
    "        # print(f\"Decoder outputs: {decoder_outputs.shape}\")\n",
    "\n",
    "        # Fully connected layer to project to output size\n",
    "        output = self.fc(decoder_outputs.squeeze(1))  # Remove seq_len dimension, shape: (batch_size, output_size)\n",
    "        # print(f\"Final output shape: {output.shape}\")\n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 512\n",
    "output_size = y.shape[1]\n",
    "model = Seq2SeqModel(input_size, hidden_size, output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.0019\n",
      "Epoch 2/25, Loss: 0.0017\n",
      "Epoch 3/25, Loss: 0.0016\n",
      "Epoch 4/25, Loss: 0.0016\n",
      "Epoch 5/25, Loss: 0.0016\n",
      "Epoch 6/25, Loss: 0.0016\n",
      "Epoch 7/25, Loss: 0.0016\n",
      "Epoch 8/25, Loss: 0.0016\n",
      "Epoch 9/25, Loss: 0.0016\n",
      "Epoch 10/25, Loss: 0.0016\n",
      "Epoch 11/25, Loss: 0.0016\n",
      "Epoch 12/25, Loss: 0.0016\n",
      "Epoch 13/25, Loss: 0.0016\n",
      "Epoch 14/25, Loss: 0.0015\n",
      "Epoch 15/25, Loss: 0.0015\n",
      "Epoch 16/25, Loss: 0.0015\n",
      "Epoch 17/25, Loss: 0.0015\n",
      "Epoch 18/25, Loss: 0.0015\n",
      "Epoch 19/25, Loss: 0.0015\n",
      "Epoch 20/25, Loss: 0.0015\n",
      "Epoch 21/25, Loss: 0.0015\n",
      "Epoch 22/25, Loss: 0.0015\n",
      "Epoch 23/25, Loss: 0.0015\n",
      "Epoch 24/25, Loss: 0.0015\n",
      "Epoch 25/25, Loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 25\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(torch.tensor(X, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# Function to decode embeddings into text\n",
    "def decode_embedding(embedding, reference_embeddings, original_titles):\n",
    "    \"\"\"\n",
    "    Decodes an embedding by finding the closest match in the original sentences.\n",
    "\n",
    "    Args:\n",
    "        embedding: The embedding vector to decode.\n",
    "        original_sentences: List of reference sentences (titles in this case).\n",
    "        sentence_transformer_model: The pretrained SentenceTransformer model.\n",
    "\n",
    "    Returns:\n",
    "        The decoded sentence.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarity between the embedding and reference embeddings\n",
    "    similarities = cos_sim(embedding, reference_embeddings)\n",
    "\n",
    "    # Find the index of the most similar sentence\n",
    "    most_similar_idx = similarities.argmax()\n",
    "\n",
    "    return original_titles[most_similar_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_titles = articles['preprocessed_title'].tolist()\n",
    "\n",
    "# Pre-encode the original titles\n",
    "reference_embeddings = sentence_transformer.encode(original_titles)  # Shape: (num_titles, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Title: adroit envoy state case pakistan\n",
      "Ground Truth Title: reversal pakistan welcome outside help inquiry bhutto\n",
      "Predicted Title: election violence kenya\n",
      "Ground Truth Title: fighting intensifies election kenya\n",
      "Predicted Title: west bank 99 7 public land grant israel go settler\n",
      "Ground Truth Title: israel olmert curb settlement\n",
      "Predicted Title: gay marriage backer celebrate germany need hide\n",
      "Ground Truth Title: gay muslim pack dance floor\n",
      "Predicted Title: election night g iraq\n",
      "Ground Truth Title: iraqi reveler embrace new year\n"
     ]
    }
   ],
   "source": [
    "# Decode all predicted embeddings\n",
    "predicted_titles = [\n",
    "    decode_embedding(prediction, reference_embeddings, original_titles)\n",
    "    for prediction in predictions.numpy()\n",
    "]\n",
    "\n",
    "# Print sample predictions\n",
    "for i in range(5):\n",
    "    print(f\"Predicted Title: {predicted_titles[i]}\")\n",
    "    print(f\"Ground Truth Title: {original_titles[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Cosine Similarity  Jaccard Similarity  Levenshtein Distance  \\\n",
      "0                0.546575            0.090909                    40   \n",
      "1                0.875486            0.400000                    23   \n",
      "2                0.563120            0.076923                    38   \n",
      "3                0.320188            0.090909                    33   \n",
      "4                0.416743            0.000000                    25   \n",
      "...                   ...                 ...                   ...   \n",
      "105878           0.315784            0.066667                    49   \n",
      "105879           0.495784            0.142857                    28   \n",
      "105880           0.383617            0.000000                    27   \n",
      "105881           0.307145            0.000000                    43   \n",
      "105882           0.348425            0.062500                    63   \n",
      "\n",
      "        Flesch-Kincaid Grade (Ground Truth)  Flesch-Kincaid Grade (Predicted)  \n",
      "0                                      10.7                               2.9  \n",
      "1                                      13.1                               9.2  \n",
      "2                                       7.2                               3.7  \n",
      "3                                       0.5                               7.2  \n",
      "4                                       5.2                               1.3  \n",
      "...                                     ...                               ...  \n",
      "105878                                 10.3                              10.7  \n",
      "105879                                 12.3                               9.2  \n",
      "105880                                  5.6                              19.0  \n",
      "105881                                  3.7                              17.8  \n",
      "105882                                  9.5                               3.7  \n",
      "\n",
      "[105883 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.util import ngrams\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from textstat import flesch_kincaid_grade\n",
    "\n",
    "# Cosine similarity\n",
    "def compute_cosine_similarity(gt_titles, pred_titles, sentence_transformer):\n",
    "    gt_embeddings = [sentence_transformer.encode(title) for title in gt_titles]\n",
    "    pred_embeddings = [sentence_transformer.encode(title) for title in pred_titles]\n",
    "    similarities = [\n",
    "        cosine_similarity([gt], [pred])[0][0]\n",
    "        for gt, pred in zip(gt_embeddings, pred_embeddings)\n",
    "    ]\n",
    "    return similarities\n",
    "\n",
    "# Jaccard similarity\n",
    "def compute_jaccard_similarity(gt_titles, pred_titles):\n",
    "    jaccard_scores = []\n",
    "    for gt, pred in zip(gt_titles, pred_titles):\n",
    "        gt_set = set(gt.split())\n",
    "        pred_set = set(pred.split())\n",
    "        intersection = len(gt_set & pred_set)\n",
    "        union = len(gt_set | pred_set)\n",
    "        jaccard_scores.append(intersection / union if union > 0 else 0)\n",
    "    return jaccard_scores\n",
    "\n",
    "# Levenshtein distance\n",
    "def compute_levenshtein_distances(gt_titles, pred_titles):\n",
    "    return [levenshtein_distance(gt, pred) for gt, pred in zip(gt_titles, pred_titles)]\n",
    "\n",
    "# Flesch-Kincaid readability\n",
    "def compute_flesch_kincaid_readability(titles):\n",
    "    return [flesch_kincaid_grade(title) for title in titles]\n",
    "\n",
    "# Example usage\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Calculate metrics\n",
    "cosine_similarities = compute_cosine_similarity(original_titles, predicted_titles, sentence_transformer)\n",
    "jaccard_similarities = compute_jaccard_similarity(original_titles, predicted_titles)\n",
    "levenshtein_distances = compute_levenshtein_distances(original_titles, predicted_titles)\n",
    "flesch_kincaid_ground = compute_flesch_kincaid_readability(original_titles)\n",
    "flesch_kincaid_predicted = compute_flesch_kincaid_readability(predicted_titles)\n",
    "\n",
    "# Compile results\n",
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    \"Cosine Similarity\": cosine_similarities,\n",
    "    \"Jaccard Similarity\": jaccard_similarities,\n",
    "    \"Levenshtein Distance\": levenshtein_distances,\n",
    "    \"Flesch-Kincaid Grade (Ground Truth)\": flesch_kincaid_ground,\n",
    "    \"Flesch-Kincaid Grade (Predicted)\": flesch_kincaid_predicted,\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Jaccard Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Flesch-Kincaid Grade (Ground Truth)</th>\n",
       "      <th>Flesch-Kincaid Grade (Predicted)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.546575</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>40</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>23</td>\n",
       "      <td>13.1</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.563120</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>38</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.320188</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.416743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cosine Similarity  Jaccard Similarity  Levenshtein Distance  \\\n",
       "0           0.546575            0.090909                    40   \n",
       "1           0.875486            0.400000                    23   \n",
       "2           0.563120            0.076923                    38   \n",
       "3           0.320188            0.090909                    33   \n",
       "4           0.416743            0.000000                    25   \n",
       "\n",
       "   Flesch-Kincaid Grade (Ground Truth)  Flesch-Kincaid Grade (Predicted)  \n",
       "0                                 10.7                               2.9  \n",
       "1                                 13.1                               9.2  \n",
       "2                                  7.2                               3.7  \n",
       "3                                  0.5                               7.2  \n",
       "4                                  5.2                               1.3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Assessment of Model:\n",
      "Average Cosine Similarity: 0.6049\n",
      "Average Jaccard Similarity: 0.2923\n",
      "Average Levenshtein Distance: 28.03\n",
      "Average Readability (Ground Truth): 7.22\n",
      "Average Readability (Predicted): 7.29\n",
      "Readability Gap: 0.08 (Lower is better)\n"
     ]
    }
   ],
   "source": [
    "average_cosine = results_df[\"Cosine Similarity\"].mean()\n",
    "average_jaccard = results_df[\"Jaccard Similarity\"].mean()\n",
    "average_levenshtein = results_df[\"Levenshtein Distance\"].mean()\n",
    "\n",
    "# Compute readability averages\n",
    "average_readability_ground = results_df[\"Flesch-Kincaid Grade (Ground Truth)\"].mean()\n",
    "average_readability_predicted = results_df[\"Flesch-Kincaid Grade (Predicted)\"].mean()\n",
    "\n",
    "# Print results\n",
    "print(\"General Assessment of Model:\")\n",
    "print(f\"Average Cosine Similarity: {average_cosine:.4f}\")\n",
    "print(f\"Average Jaccard Similarity: {average_jaccard:.4f}\")\n",
    "print(f\"Average Levenshtein Distance: {average_levenshtein:.2f}\")\n",
    "print(f\"Average Readability (Ground Truth): {average_readability_ground:.2f}\")\n",
    "print(f\"Average Readability (Predicted): {average_readability_predicted:.2f}\")\n",
    "\n",
    "# Compare readability\n",
    "readability_gap = abs(average_readability_ground - average_readability_predicted)\n",
    "print(f\"Readability Gap: {readability_gap:.2f} (Lower is better)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
